{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"Traning model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"R4fHaKN_up2C","colab_type":"code","colab":{}},"source":["from numpy import array\n","from numpy import argmax\n","from pickle import load\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.utils import plot_model\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Embedding\n","from keras.layers import Dropout\n","from keras.models import load_model\n","from keras.layers.merge import add\n","from keras.callbacks import ModelCheckpoint\n","from nltk.translate.bleu_score import corpus_bleu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3aUIzu9up2N","colab_type":"code","colab":{}},"source":["def load_doc(filename):\n","    file = open(filename, 'r')\n","    text = file.read()\n","    file.close()\n","    return text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EiBrZtofup2T","colab_type":"code","colab":{}},"source":["def load_set(filename):\n","    doc = load_doc(filename)\n","    dataset = list()\n","    for line in doc.split('\\n'):\n","        if len(line) < 1:\n","            continue\n","        identifier = line.split('.')[0]\n","        dataset.append(identifier)\n","    return set(dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mY5LSJthup2Y","colab_type":"code","colab":{}},"source":["def load_clean_descriptions(filename, dataset):\n","    doc = load_doc(filename)\n","    descriptions = dict()\n","    for line in doc.split('\\n'):\n","        tokens = line.split()\n","        image_id, image_desc = tokens[0], tokens[1:]\n","        if image_id in dataset:\n","            if image_id not in descriptions:\n","                descriptions[image_id] = list()\n","# wrap description in tokens\n","                desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n","# store\n","            descriptions[image_id].append(desc)\n","    return descriptions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSh8hcXpup2c","colab_type":"code","colab":{}},"source":["def load_photo_features(filename, dataset):\n","    all_features = load(open(filename, 'rb'))\n","    features = {k: all_features[k] for k in dataset}\n","    return features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3SBiw7klup2h","colab_type":"code","colab":{}},"source":["def to_lines(descriptions):\n","    all_desc = list()\n","    for key in descriptions.keys():\n","        [all_desc.append(d) for d in descriptions[key]]\n","    return all_desc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bMkjEQzlup2m","colab_type":"code","colab":{}},"source":["def create_tokenizer(descriptions):\n","    lines = to_lines(descriptions)\n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(lines)\n","    return tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7yWAGXQQup2r","colab_type":"code","colab":{}},"source":["def max_length(descriptions):\n","    lines = to_lines(descriptions)\n","    return max(len(d.split()) for d in lines)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3m2hERtlp95","colab_type":"code","colab":{}},"source":["def max_length(descriptions):\n","    lines = to_lines(descriptions)\n","    return max(len(d.split()) for d in lines)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l0f7DEO0lszQ","colab_type":"code","colab":{}},"source":["def word_for_id(integer, tokenizer):\n","    for word, index in tokenizer.word_index.items():\n","        if index == integer:\n","            return word\n","    return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fON3G89WlwPG","colab_type":"code","colab":{}},"source":["# generate a description for an image\n","def generate_desc(model, tokenizer, photo, max_length):\n","# seed the generation process\n","    in_text = 'startseq'\n","# iterate over the whole length of the sequence\n","    for _ in range(max_length):\n","# integer encode input sequence\n","        sequence = tokenizer.texts_to_sequences([in_text])[0]\n","        sequence = pad_sequences([sequence], maxlen=max_length)\n","        yhat = model.predict([photo,sequence], verbose=0)\n","# convert probability to integer\n","        yhat = argmax(yhat)\n","# map integer to word\n","        word = word_for_id(yhat, tokenizer)\n","        if word is None:\n","            break\n","        in_text += ' ' + word\n","        if word == 'endseq':\n","            break\n","    return in_text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AcA6q-iBl1Dt","colab_type":"code","colab":{}},"source":["def cleanup_summary(summary):\n","    index = summary.find('startseq ')\n","    if index > -1:\n","        summary = summary[len('startseq '):]\n","    index = summary.find(' endseq')\n","    if index > -1:\n","        summary = summary[:index]\n","    return summary"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWGZ9eOol2zZ","colab_type":"code","colab":{}},"source":["def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n","    actual, predicted = list(), list()\n","    for key, desc_list in descriptions.items():\n","# generate description\n","        yhat = generate_desc(model, tokenizer, photos[key], max_length)\n","# clean up prediction\n","        yhat = cleanup_summary(yhat)\n","# store actual and predicted\n","        references = [cleanup_summary(d).split() for d in desc_list]\n","        actual.append(references)\n","        predicted.append(yhat.split())\n","# calculate BLEU score\n","    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n","    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n","    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n","    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_9YBfoSup2w","colab_type":"code","colab":{}},"source":["def create_sequences(tokenizer, max_length, descriptions, photos):\n","    X1, X2, y = list(), list(), list()\n","    for key, desc_list in descriptions.items():\n","        for desc in desc_list:\n","# encode the sequence\n","            seq = tokenizer.texts_to_sequences([desc])[0]\n","# split one sequence into multiple X,y pairs\n","            for i in range(1, len(seq)):\n","# split into input and output pair\n","                in_seq, out_seq = seq[:i], seq[i]\n","# pad input sequence\n","                in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","# encode output sequence\n","                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n","                X1.append(photos[key][0])\n","                X2.append(in_seq)\n","                y.append(out_seq)\n","    return array(X1), array(X2), array(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iqoyUxaVup21","colab_type":"code","colab":{}},"source":["def define_model(vocab_size, max_length):\n","# feature extractor model\n","    inputs1 = Input(shape=(4096,))\n","    fe1 = Dropout(0.5)(inputs1)\n","    fe2 = Dense(256, activation='relu')(fe1)\n","# sequence model\n","    inputs2 = Input(shape=(max_length,))\n","    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n","    se2 = Dropout(0.5)(se1)\n","    se3 = LSTM(256)(se2)\n","# decoder model\n","    decoder1 = add([fe2, se3])\n","    decoder2 = Dense(256, activation='relu')(decoder1)\n","    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n","# tie it together [image, seq] [word]\n","    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n","# compile model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam')\n","# summarize model\n","    model.summary()\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XebPnIMsup27","colab_type":"code","outputId":"1af67a45-193c-4e52-96a1-8966dcb41007","executionInfo":{"status":"ok","timestamp":1564752983059,"user_tz":-330,"elapsed":4772,"user":{"displayName":"Vipin Kant","photoUrl":"","userId":"11971622915661998281"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["filename = 'Flickr_8k.trainImages.txt'\n","train = load_set(filename)\n","print('Dataset: %d' % len(train))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset: 6000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gj71yBXFup3D","colab_type":"code","outputId":"6f2a63ea-b0fa-4444-8561-4b6c790d6089","executionInfo":{"status":"ok","timestamp":1564752983420,"user_tz":-330,"elapsed":1872,"user":{"displayName":"Vipin Kant","photoUrl":"","userId":"11971622915661998281"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_descriptions = load_clean_descriptions('descriptions.txt', train)\n","print('Descriptions: train=%d' % len(train_descriptions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Descriptions: train=6000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tOmTeD0Fup3L","colab_type":"code","outputId":"65dc50fb-6e75-412f-b2e0-692d6f52f000","executionInfo":{"status":"ok","timestamp":1564753898493,"user_tz":-330,"elapsed":1112,"user":{"displayName":"Vipin Kant","photoUrl":"","userId":"11971622915661998281"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_features = load_photo_features('features.pkl', train)\n","print('Photos: train=%d' % len(train_features))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Photos: train=6000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0aTATq-Zup3Q","colab_type":"code","outputId":"ae4560d2-a6d7-46a1-ad49-b548211cbb64","executionInfo":{"status":"ok","timestamp":1564753901472,"user_tz":-330,"elapsed":1084,"user":{"displayName":"Vipin Kant","photoUrl":"","userId":"11971622915661998281"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tokenizer = create_tokenizer(train_descriptions)\n","vocab_size = len(tokenizer.word_index) + 1\n","print('Vocabulary Size: %d' % vocab_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Vocabulary Size: 3857\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8SacvJ2Lup3X","colab_type":"code","outputId":"895a05b6-7578-4bd1-ec16-3c848aa62a0c","executionInfo":{"status":"ok","timestamp":1564753903820,"user_tz":-330,"elapsed":1096,"user":{"displayName":"Vipin Kant","photoUrl":"","userId":"11971622915661998281"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["max_length = max_length(train_descriptions)\n","print('Description Length: %d' % max_length)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Description Length: 30\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pr6XtDI_up3d","colab_type":"code","colab":{}},"source":["X1train, X2train, ytrain = create_sequences(tokenizer, max_length, train_descriptions,train_features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kVFu1jHrup3k","colab_type":"code","outputId":"cd83434e-9e10-4df2-e188-8c763a67080c","executionInfo":{"status":"ok","timestamp":1564753913350,"user_tz":-330,"elapsed":5395,"user":{"displayName":"Vipin Kant","photoUrl":"","userId":"11971622915661998281"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["filename = 'Flickr_8k.devImages.txt'\n","test = load_set(filename)\n","print('Dataset: %d' % len(test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset: 1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IlKAOFzlup3t","colab_type":"code","outputId":"e9a89b05-57d8-41c0-b96c-389606fb2b9d","executionInfo":{"status":"ok","timestamp":1564753913352,"user_tz":-330,"elapsed":3083,"user":{"displayName":"Vipin Kant","photoUrl":"","userId":"11971622915661998281"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_descriptions = load_clean_descriptions('descriptions.txt', test)\n","print('Descriptions: test=%d' % len(test_descriptions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Descriptions: test=1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q_Em43ddup30","colab_type":"code","outputId":"f97b5ba6-829b-424e-9656-51b28c0f0e67","executionInfo":{"status":"ok","timestamp":1564753913353,"user_tz":-330,"elapsed":1502,"user":{"displayName":"Vipin Kant","photoUrl":"","userId":"11971622915661998281"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_features = load_photo_features('features.pkl', test)\n","print('Photos: test=%d' % len(test_features))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Photos: test=1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PRAR4vCeup38","colab_type":"code","colab":{}},"source":["X1test, X2test, ytest = create_sequences(tokenizer, max_length, test_descriptions,test_features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JLyIrtLWup4G","colab_type":"code","outputId":"ff51962e-c44a-48ca-a317-d6012895ca51","executionInfo":{"status":"ok","timestamp":1564753923652,"user_tz":-330,"elapsed":1430,"user":{"displayName":"Vipin Kant","photoUrl":"","userId":"11971622915661998281"}},"colab":{"base_uri":"https://localhost:8080/","height":836}},"source":["model = define_model(vocab_size, max_length)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0802 13:52:01.648682 140411071215488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0802 13:52:01.700470 140411071215488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0802 13:52:01.712192 140411071215488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0802 13:52:01.730852 140411071215488 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0802 13:52:01.755097 140411071215488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0802 13:52:02.279909 140411071215488 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0802 13:52:02.346403 140411071215488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0802 13:52:02.372747 140411071215488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 30)           0                                            \n","__________________________________________________________________________________________________\n","input_1 (InputLayer)            (None, 4096)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 30, 256)      987392      input_2[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 4096)         0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 30, 256)      0           embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 256)          1048832     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   (None, 256)          525312      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 256)          0           dense_1[0][0]                    \n","                                                                 lstm_1[0][0]                     \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 3857)         991249      dense_2[0][0]                    \n","==================================================================================================\n","Total params: 3,618,577\n","Trainable params: 3,618,577\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bGalylL3up4L","colab_type":"code","colab":{}},"source":["checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', verbose=1,\n","save_best_only=True, mode='min')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QtjtSEDYup4P","colab_type":"code","outputId":"10fce1e5-1318-4c4a-82f9-7f7083839300","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# fit model\n","model.fit([X1train, X2train], ytrain, epochs=10, verbose=2, callbacks=[checkpoint],validation_data=([X1test, X2test], ytest))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 61317 samples, validate on 10095 samples\n","Epoch 1/10\n"," - 413s - loss: 3.3867 - val_loss: 4.0425\n","\n","Epoch 00001: val_loss did not improve from 4.01085\n","Epoch 2/10\n"," - 411s - loss: 3.2634 - val_loss: 4.0812\n","\n","Epoch 00002: val_loss did not improve from 4.01085\n","Epoch 3/10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oyW1Inaxupgf","colab_type":"code","outputId":"455cd91d-670a-4f96-cc62-5b6971c7c1bf","executionInfo":{"status":"ok","timestamp":1564763834221,"user_tz":-330,"elapsed":85521,"user":{"displayName":"Vipin Kant","photoUrl":"","userId":"11971622915661998281"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["filename = 'model.h5'\n","model = load_model(filename)\n","# evaluate model\n","evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["BLEU-1: 0.208424\n","BLEU-2: 0.109230\n","BLEU-3: 0.075719\n","BLEU-4: 0.030590\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_8VBmOAdhAQf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4YZon7eTw6WO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}